---

layout: post

title:  "AWS - 이론정리3"

date:   2022-02-05

categories: AWS

tags: AWS

image: /post_img/aws.jpg

---



#### EC2 인스턴스 메타데이터

- 기본적으로 EC2 인스턴스가 스스로 학습하도록 합니다. ( IAM 역할을 해당 목적으로 사용하지 않아도 됩니다. )
- EC2 인스턴스는 누구인지, URL이 무엇인지를 알아야 합니다. - http://169.254.169.254/latest/meta-data
- AWS에 대한 내부 IP로 개인 PC에서는 작동하지 않고, 인스턴스에서만 작동합니다.
- 이를통해 메타데이터로부터 IAM 역할 이름을 검색할 수 있습니다. ( 이를 통해 IAM 정책 테스트를 할 수 있습니다. )
- 메타데이터는 EC2인스턴스에 대한 정보이며 사용자 데이터로 EC2 인스턴스 스크립트를 런칭한 곳이 어디였는지 등 알 수 있습니다.



```shell
curl http://169.254.169.254/latest/meta-data/[알고싶은 정보]
```

<br>

#### AWS SDK

- AWS를 CLI를 사용하지 않고, 어플리케이션 코드에서 직접 동작 할 수 있습니다.
- Boto3 라고 불리는 Python SDK가 가장 유명합니다. ( AWS CLI가 Boto3로 만들었습니다. )
- 지역을 설정하지 않으면 default 값인 us-east-1이 선택되니 지역을 선택해야합니다.

<br>

#### S3 MFA Delete

- MFA - Delete는 MFA를 사용하는 다단계 인증이며, S3에서 중요한 작업을 수행하기 위해 사용합니다.
- MFA - Delete를 사용하기 위해서는 S3버킷에 Versioning이 활성화 되어야 합니다.
- MFA가 필요한 상황
  - 영구적으로 object version을 삭제할 때
  - 버킷을 suspend versioning 할 때 (버저닝 비활성화) 
- 버킷 소유자만, MFA - Delete를 활성화/비활성화 해야합니다. ( root 사용자 )
- CLI를 통해서만 가능함.

<br>

#### S3 Default Encryption 

- 기본적으로 S3에 들어가는 모든 Object는 암호화 되어야합니다. ( 암호화 옵션을 사용하면 암호화됩니다. )

<br>

#### S3 Access Logs

- 감사의 목적으로 모든 액세스를 S3버킷에 기록, 즉 모든 계정의 모든 승인 또는 거부된 요청들을 기록합니다.
- 이러한 로그는 다른 S3에 저장되어야 하며, 이후 Amazone Athena를 사용하여 분석

<br>

#### S3 Replication ( CRR & SRR )

- 이를 위해서는 Versioning이 활성화 되어야 합니다.
- CRR - 다른 리전으로 복제
- SRR - 같은 리전으로 복제
- 버킷은 서로 다른 계정에 존재 할 수 있습니다.
- 복제는 비동기식으로 일어나며, 매우 빠르게 진행됩니다.
- 이를 위해서는 IAM 롤이 생성되어야 합니다.
- 복제를 진행한 이후에 새로운 오브젝트부터 복제가 됩니다. ( 기존 오브젝트는 복제 X )

<br>

#### S3 pre-signed URLs

- SDK or CLI를 통해서 pre-signed URLs를 생성 할 수 있습니다.
- 만료시간을 설정 할 수 있는데 - 기본값은 3600초입니다.
- 기본적으로 pre-signed URLs을 줄 때, 그 권한을 상속합니다. ( 따라서, 그 권한을 이용해서 GET/PUT등의 작업을 수행 할 수 있습니다. )

<br>

#### S3 Storage Classes

- S3 Standard 
- S3 Standard - Infrequent Access (IA) - 백업용으로 주로 사용
- S3 One Zone - Infrequent Access - 온프로미스 데이터 백업, 썸네일 등
- S3 Interlligent Tiering - 모니터링을 통해 어떤 S3가 적합한지 판단하고 자동으로 처리
- Glacier - 마크네틱 스토리지의 대체용으로 좋음  버킷이아니라 볼트라는 단위를 이용
  - 회수하는데 시간이 걸립니다. ( Expedited - 1~ 5 minutes, Standard 3~5 hours, Bulk 5~12 hours, 최소 보관기간 90일, 즉 장기적으로 존재해야 하는 파일 )
- Glacier Deep Archive - 회수하는데 더 오래걸리지만 가격이 더 쌈 ( Standard 12hours, Bulk 48 hours, 최소보관기간 180일 )
- S3 Reduced Redundancy Storage - 지금은 사용하지 않음

<br>

#### S3 수명주기

- 수명주기 구성을 통해 자동으로 class이동이 가능 ( 60일 이후 IA로 이동 등 )
- 일정시간 이후 파일을 삭제하는 것도 가능

<br>

#### S3 Analytics - Storage Class Analysis

- S3에서 IA로 이동하는게 언제가 적절한지 분석하기 위해 사용합니다.
- 오직 Standard 에서 Standard-IA에서만 작동합니다.
- 이 기능을 활성화하면 매일 업데이트 됩니다.
- 수명주기를 계산하기 위한 제일 좋은 첫 방법입니다.

<br>

#### S3 Performance

- 100메가 이상의 파일을 업로드 할 때는 멀티 파일 업로드를 권장합니다. ( 5기가 이상은 필수 )
- Transfer Acceleration - 엣지 로케이션을 이용해서 전송속도를 늘리는 방법
- Byte-Range-Fetches - 바이트단로 병렬 Get 진 ( 실패시 더 작은 단위로 쪼갬 - 더 나은 복원력을 가집니다. )
- 필요한 부분만 가져옵니다. (헤더만 가져온다 등 )

<br>

#### S3 Select

- SQL을 이용해서 필요한 데이터만 필터링 할 수 있습니다.
- 적은 네트워크를 사용하고, 적은 CPU 코스트를 사용하게 됩니다.

<br>

#### S3 Event Notifications

- S3에 생성 삭제등 액션이 취해졌을 때, 알림 규칙을 통해 행동을 취할 수 있음 (SNS, SQS, Lambda 등)

<br>

#### S3 - Requesters Pays

- 일반적으로 버킷 소유자가 S3에 대한 네트워킹 비용을 지불하지만, 버킷 소유자 대신 요청자가 네트워킹 비용을 지불하는 방법

<br>

#### Amazon Athena

- 서버리스 분석 서비스
- SQL을 이용
- CSV, JSON, ORC, Arbo and Parquet

<br>

#### Glacier Vault Lock

- WORM - Write Once Read Many 
- 볼트를 잠굼으로써, 수정할 수 없습니다. ( 변경되지 않았음을 보장 )

<br>

#### AWS CloudFront

- CloudFront는 콘텐츠 전송 네트워크 입니다. ( CDN )
- 읽기 성능을 높힙니다. ( 엣지로케이션으로 분배되기 때문에 )
- S3 or HTTP
- Geo Restriction을 설정 할 수 있음 ( 화이트리스트, 블랙리스트 지정 )

<br>

#### CloudFront Signed URL / Signed Cookies

- 일정 사람들에게 액세스 권한을 부여하고 CloudFront 배포에서 누가 액세스 권한이 있고 어떤 것에 액세스 권한이 있는지 보고 싶을 때 사용
- Signed URL - 개별 파일에 대한 액세스를 제공합니다. (파일당 하나의 URL을 얻습니다.)
- Signed Cookies - 여러 파일에 쿠키를 재사용 할 수 있습니다.

<br>

#### Unicast Ip VS Anycast IP

- Unicast IP - 하나의 서버가 IP주소를 보유합니다. (12로 시작하면, 12쪽으로 보내는 등)
- Anycast IP - 모든 서버가 동일한 IP주소를 보유합니다. (가장 가까운 서버로 전송)

<br>

#### Global Accelerator

- 앱을 라우팅하기 위해 AWS 내부 네트워크를 이용 ( Anycast IP를 이용하는 방식 )

<br>

#### Snowball Edge

- 테라바이트, 페타바이트단위에 데이터를 전송하는데 효과적
- 두가지의 버전
  - Snowball Edge Storage Optimized
    - 80테라바이트 용량의 하드웨어 디스크를 포함하며, 볼륨, S3로의 전환을 돕습니다.
  - Snowball Edge Compute Optimized
    - 42테라바이트의 용량을 제공합니다.
- 데이터 센터 이전, 재해복구 등을 위해 사용되는 기기

<br>

#### Snowcone

- snowcone은 작은 기기입니다. ( 스노우볼 엣지보다 훨씬 작음 )
- 견고하고 안전하며 가혹한 환경을 견딜 수 있습니다. ( 사막, 물속등에서 사용 가능 ), 2.1kg
- 8TB의 용량을 제공합니다.
- 스노우볼 엣지를 사용하기에 공간이 제한적인 곳에서 자주 사용 ( 드론 위에도 놓을 수 있음 )

<br>

#### Snowmobile

- 실제 트럭
- 1EB (1000pb)의 용량을 지원하는 매우 큰 저장소 ( 단 한대당 100PB를 지원하므로 10대를 사용했을 때 용량 )
- GPS와 연중무휴 영상 감지 시스템이 탑재되어있음. ( 데이터를 전송하는 아주 안전한 방법 )
- 10pb이상의 데이터를 전송할 때 적절한 사례

이러한 snow family들은 바로 Glacier가 될 수는 없으며, S3에서 수명주기를 이용한 전환이 필요

 <br>

#### Hybrid Cloud for Stroage

- 일부는 클라우드에 있고, 일부는 온프레미스에 있는 것을 칭함
-  여러가지 사유로 하이브리드 클라우드를 이용 ( 보안, IT정책 등 )
- AWS Storage Gateway를 통해 가능

<br>

#### Storage Gateway

- S3와 온프레미스를 연결합니다.
- File Gateway
  - NFS와 SMB프로토콜을 이용해서 액세스
  - 파일 게이트웨이는 IAM 규칙을 통해 버킷에 연결
  - 대부분 최근 사용된 데이터가 캐쉬됩니다.
  - 사용자 인증이 필요한 경우, 사용자 인증을 수행하기 위해 온프레미스와 Active Directory와 통합 될 수 있습니다.
- Volume Gateway
  - iSCSI프로토콜을 이용
  - EBS 스냅샷을 가지며, 필요한 경우 온프레미스 볼륨을 복원하는데 사용
    - Cached volume - 가장 최근에 데이터에는 대기시간이 짧은 액세스를 제공
    - Stored volume - 전체 데이터 세트가 온프레미스인 stored volume에 있고, S3에 대한 예약된 백업이 있습니다. 
- Tape Gateway
  - 테이프 백업 시스템 같은 물리적 시스템을 사용하는 경우, 테이프가 클라우드에 백업됩니다. 

<br>

#### FSx File Gateway

- AWS에서 제공되는 Windows 파일 서버용 기본 액세스 제공
- 자주 액세스하는 데이터의 로컬 캐시됨

<br>

#### Amazone FSx

- FSx는 AWS의 관리형 서비스입니다. ( 타사대비 높은 성능을 보여줍니다. )
- FSx for Windows
  - EFS의 경우 POSIX시스템으로 리눅스 시스템에서만 작동합니다.
  - 이는 Windows용 파일 공유 시스템입니다.
  - SMB 프로토콜 및 Windows NTFS, Active Directory 통합 지원
- FSx for Lustre
  - 대규모 컴퓨팅용 병렬 분산 파일 시스템
  - L(inux) + ustre(cluster)
  - 기계학습, 고성능 컴퓨팅에 사용

<br>

#### Transfer Family

- S3 또는 EFS 내외로 데이터 송수신하기를 원할때, S3 API를 사용하지 않고, EFS 네트워크 파일 시스템을 사용하지 않고, FTP 프로토콜을 사용하는 방법
- Transfer for FTP
- Transfer for FTPS
- Transfer for SFTP

<br>

#### SQS

- AWS에서 가장 오래된 서비스
- 완전 관리형 서비스로, decouple applications
- 큐의 메시지 수에는 제한이 없습니다.
- 기본 메세지 보관 기간은 4일 ( 최대 14일 )
- 저지연
- 메시지등 256KB 미만이여야 합니다.

<br>

#### SQS - Message Visibility Timeout

- 메세지가 풀되었을 때, 그것은 다른 컨슈머에게 보이지 않습니다.
- 이후 설정한 메시지 가시성 타임아웃이 지나면 해당 메세지가 다른 컨슈머에게 보입니다. ( 이는 타임아웃 전에 메세지를 처리해야 함을 의미 - 그렇지 않으면 중복처리가 될 가능성이 높음 )
- 만약 메세지 처리가 더 오래 걸릴것 같으면 Change Message Visibility API를 통해 다른 컨슈머에게 안보이게 할 수 있습니다.

<br>

#### Dead Letter Queue

- 반복해서 처리하지 못한 메세지를 다른 큐로 빼는 방법
- 이후 나중에 Dead Letter Queue를 분석해서 왜 성공적으로 처리되지 못했는지 분석 

<br>

#### Delay Queue

- 의도적으로 메세지에 딜레이를 주는 방법

<br>

#### Long Polling

- 메세지가 비어있는데, 폴하는 경우 계속해서 기다리게되는데 이를 롱 폴링이라고 합니다.
- 사용하는 이유
  - 지연시간을 줄이기 위해
  - API 호출 수를 줄이기 위해

<br>

#### FIFO Queue

- First in First out ( 순서를 보증합니다. )
- 초당 300개의 메시지를 받으며, 초당 3000개의 메세지를 처리 할 수 있습니다.
- 정확히 한 번 보낼수있는 기능으로, 중복을 제거하는것을 허용
- 메시지의 순서가 보장되어야 할 때 사용
- 큐의 이름이 .fifo 로 끝내야합니다.

<br>

#### SNS

- 메세지를 보내야하는데, 수신기가 여러개일 때 효과적
- 주제를 정하고, 해당 주제에대한 구독으로 이뤄짐
- 구독자는 SQS, HTTP,HTTPS, Lambda Email, SMS, Mobile Notification 이 될 수 있습니다.

<br>

#### SNS + SQS Fan Out

- SQS가 SNS를 구독하도록 설계
- SQS는 SNS가 보내는 메세지를 받고, SQS를 통해 이를 처리
- 이는 완전히 분리된 모델이며, 데이터 손실이 없습니다.
- SQS지속성을 통해 처리 지연 및 작업 재시도를 제공합니다. 

<br>

#### Kinesis

- 프로세스를 쉽게 수집하고, 스트리밍 데이터를 실시간으로 분석할 수 있습니다.
- Kinesis Data Streams - 캡쳐, 프로세스, 데이터 저장
- Kinesis Data Firehose - 실시간 데이터 로드
- Kinesis Data Analytics - 데이터 스트림 분석 ( SQL, Flink )
- Kinesis Video Stream - 비디오 관련 처리

<br>

#### Kinesis Data Stream

- 스트림은 샤드라는 단위를 가지는데, 샤드가 많을 수록, 스트림 통과를 위해 더 많은 데이터가 통과됩니다.
- 파티션키와 data blob을 통해 데이터가 전송되고, 샤드 하나당, 초당 1mb의 처리 능력을 보유합니다.
- 이후 처리된 데이터는 다시 파티션 키, Sequence no, Data Blob으로 컨슈머에게 전달됩니다. 
- 일종의 Publish - Subscribe 구조
- 컨슈머 처리는, 2가지 종류가 있으며
  - Shared - 샤드 하나당 초당 2MB, 모든 컨슈머 대상
  - enhanced - 샤드 하나당 초당 2MB, 하나의 컨슈머 대상 ( 당연히 더 비싸고, 더 많은 데이터 처리 )
- 프로비저닝된 샤드로, 원하는 만큼의 샤드를 가질 수 있음
- 데이터 보존은 1~365일
- 데이터를 재처리하고 재생성할 수 있습니다.
- Kinesis에 들어간 데이터는 삭제할 수 없습니다. (불변성)
- 같은 파티션을 공유하는 데이터는 같은 샤드로 이동합니다.

<br>

#### Kinesis Data Firehose

- 목표 위치에 데이터를 저장
- 한번에 1mb씩 데이터가 업로드
- 람다 함수를 생성하여, 일부 스팸 수정을 수행하기 위해 레코드 변환
- 해당 데이터를 목표 데이터베이스에 쓰기 위해 데이터 배치를 채우기 시작 ( 순간적으로 쓰지 않고, 효율적으로 작성하기 위해 배치로 모아서 처리 시도 )
- 준 실시간 서비스라고 불림
- 목적지 : S3, Redshift, ElasticSearch
- datadog, splunk, new relic, mongoDB같은 타 파트너사도 가능
- 커스텀을 통해 HTTP Endpoint도 가능
- 처리를 실패한 데이터는 이후 S3 백업 버킷으로 보낼 수 있습니다.

<br>

#### Docker Containers Management

- ECS - 컨테이너 서비스
- Fargate - 서버리스 컨테이너 플랫폼
- EKS - 쿠버네티스 서비스

<br>

#### ECS - Elastic Container Service

- 도커를 AWS에서 사용하는 방법
- 프로비전 / 인프라 유지를 해야함
- ELB와 함께 사용

<br>

#### Fargate

- 도커를 AWS에서 사용하는 방법
- 인프라스트럭쳐를 제공할 필요 없음 - 서버리스
- AWS가 Run할 컨테이너가 얼마나 많은 CPU/RAM을 필요로 하는지를 계산하여 실행

<br>

#### ECR - Elastic Container Registry

- AWS에 컨테이너를 저장하고,관리하고, 배치하는데 사용되는 서비스
- 모든 이미지는 S3의 지원을 받아 보안, 버저닝, 수명주기 등의 기능을 지원

<br>

#### EKS - Elastic Kubernates Service

- AWS에서 쿠버네티스 클러스터를 지원
- 두가지의 모드를 지원
  - EC2 실행모드 - EC2처럼 작업자 노드를 배치하는 경우
  - Fargate 모드 - 서버없는 컨테이너를 배치하고 싶은 경우

<br>

#### Lambda 제한

- 메모리 : 128mb ~ 10기가 
- 최대 실행 시간 : 900초
- 환경변수 : 4kb
- function container : 512mb
- 동시 실행 : 1000회
- 파일 : 50MB ( 압축하지 않을땐, 250 MB )
- 큰 파일이 필요할 땐 /tmp 디렉토리 사용

<br>

#### Lambda Edge

- 글로벌 lambda 함수를 운영할 때, 적절
- CloudFront CDN으로, 세계 각 지역을 따라 Lambda 함수를 배치
- 저지연을 요구하거나, 서버를 관리하지 않기 때문에 전 세계에 배치하기 좋음

<br>

#### Dynamic DB

- 가용성이 높고, 데이터는 다수의 AZ를 지나 자동으로 복제
- NOSQL
- 워크로드, 확장성이 좋음
- 테이블 안에서 일초에 수백번 요청 가능 
- 빠르고 일관된 성능을 가지고 있음
- 저지연
- 보안, 권한부여, 관리에 좋음
- 테이블형태로 생성, 각각은 프라이머리 키가 있음
- 각 아이템과 행은 특성을 가지고 있으며, 시간에 따라 추가될 수 있음
- 최대 아이템 사이즈는 400kb로, 큰 개체를 저장하기에는 적절하지 않음

<br>

#### Read/Write Capacity Modes

- 테이블 얼마나 많은 읽기와 쓰기 용량을 필요로 하는지 정의할 필요가 있습니다.
- 두개의 모드
  - 프로비전 모드(기본값) - 테이블을 보유하기 원하는 초당 읽기 쓰기 숫자를 미리 명시, 용량은 미리 계획되어야 하며, 공급한 모든것에 대한 비용을 지불, 오토스케일링을 통해 자동 스케일링 할 수 있습니다. 패턴을 예측할 수 있거나 부드럽게 작용할 때 적절
  - 온디맨드 모드 - 워크로드에 따라 용량을 줄이고 늘림. 자동으로 읽기와 쓰기를 받아들이므로, 용량 계획이 필요하지않음, 온디멘드 모드는 유연하지만, 프로비전모드보다 훨씬 비쌈

<br>



#### DynamoDB Accelerator ( DAX )

- 가용성이 뛰어난 인메모리 캐시
- 읽기 데이터를 캐시에 저장함으로 읽기 혼잡을 해결
- 캐시데이터를, microseconds의 지연시간을 가지게 함
- 어떤 종류의 애플리케이션 로직도 바꿀 필요 없이 이용가능
- 데이터는 5분(기본값) TTL 만료

<br>

#### DAX와 ElastiCache의 차이

- DAX는 DynamoDB를 위한 캐시
- 애플리케이션이 DynamoDB에 접속하기 위해 API를 변경하지 않습니다.

<br>

#### DynamoDB Sterams

- 테이블의 아이템 레벨 수정을 나타내는 정렬된 데이터 스트림입니다. ( 아이템을 생성하고 업데이트하고 삭제할 때마다 DynamoDB스트림으로 종결 )
- 기록들은 Kinesis, Lambda 로 보내지고, Kinesis Client Library 애플리케이션에 의해 읽혀집니다.
- DynamoDB 스트림의 데이터는 24시간까지 보관되서, 빨리 처리하는 것은 사용자에 달려있습니다.
- 테이블의 실시간 변화에 대응하고, 사용자에게 환영 이메일을 보내고, 분석하고, 데이터를 변환하거나 할 때 적절

<br>

#### DynamoDB Global Tables

- 테이블이 여러 영역에 걸쳐있습니다. ( 영역간의 양방향 복제가 이루어집니다. )
- 저지연을 가지게 되는 장점

<br>

#### DynamoDB - TTL

- 만료시간을 통해, 일정 시간이 지나고 데이터가 삭제됩니다.

<br>

#### DynamoDB - Indexes

- 두가지의 인덱스가 존재
  - GSI - Global Secondary Indexes
  - LSI - Local Secondary Indexes
- 프라이머리  키 이외의 속성에 대한 쿼리를 수행하게 도와줍니다.

<br>

#### DynamoDB - Transactions

- Transcations은 두개의 테이블을 쓸 수 있게 하거나, 모두 쓰지 않게 합니다.

<br>

#### API Gateway

- lambda와 통합 할 수 있습니다. 
- WebSocket 프로토콜을 지원하기 때문에, API Gateway를 통한 2개의 다른 방법으로 실시간 스트리밍 할 수 있습니다.
- 버전 관리를 통해 버전1에서 버전2로 클라이언트를 망치지 않고 좋은 환경을 구축 ( 개발, 테스트 및 개발 환경을 포함 )
- 인증 및 허가를 위해 
- 너무 많은 요청을 하는 경우, API 키를 생성하고 요청을 조절 
- 일반 표준을 사용
- 호출이 정확한지 API Gateway 단계에서 요청과 응답을 변환하고 검증 할 수 있습니다.
- 캐시할 수 있습니다.



<br>

#### API Gateway - Integration

- Lambda
  - 완전한 서버리스 애플리케이션을 하는 것은, 가장 일반적이고 쉬움
- HTTP
  - 뒤에 있는 어떤 HTTP 엔드포인트도 노출 할 수 있음 (rate limiting, cashing user authentications 등 )
- AWS Service
  - AWS API를 노출 할 수 있습니다.

<br>

#### API Gateway - Endpoint Types

- Edge-Optimized (기본값) : 글로벌 클라이언트를 위한 것으로, 세계 어디에서나 접속 할 수 있고, 효율적이며, 요구들의 대기 시간을 단축하는 Edge Location과 통하는 것을 의미
- Regional : Edge Location을 사용하기 싫을 때
- Private : VPC 내부로 부터, 접속 할 수 있고, ENI를 위해 인터페이스 VPC 엔드포인트를 사용

<br>

#### API Gateway 보안

- IAM Permission (Sig v4)
- Lambda Authorizer (Custom Authorizer)
- Cognito User Pools

<br>

#### Cognito

- 사용자에게 신분을 제공할 때 사용
- Cognito User Pools
  - 앱유저와 상호작용
  - API Gateway와 연결
- Cognito Identity Pools
  - AWS 증명서를 앱사용자에 직접 제공하여, AWS자원에 직접 접속 할 수 있습니다.
  - ID 제공자로 Cognito User Pool와 통홥
- Cognito Sync
  - 디바이스에서 Cognito로 데이터를 동기화하고 더이상 사용되지 않으며, AppSync로 대체

<br>

#### AWS SAM - Serverless Application Model

- 서버리스 애플리케이션을 개발하고, 배치하는 틀
- 서버리스 애플리케이션의 모든 구성은 YAML코드에서 이뤄집니다.

<br>

#### RDS

- 프로비전 해야합니다. (EC2 인스턴스 & EBS 볼륨)
- Read Replicas 와 멀티 AZ 지원
- IAM, KMS, SG, SSL 지원
- 백업, 스냅샷
- 클라우드 와치를 통한 모니터링
- 시스템 대체작동 이나 유지보수 문제가 발생했을 때, 다운타운이 매우 적습니다. ( EC2, EBS의 수동 개입을 암시 )

<br>

#### Aurora

- PostgreSQL, MySQl과 호환
- 3 AZ에 6개의 replicas 생성
- 자동으로 핸들링
- 다중 AZ, Auto Scaling Read Replica
- Global 서비스
- 10GB ~ 128TB의 오토스켈링
- Aurora Serveless도 존재
- Aurora Multi Master로 failover 지원

<br>

#### ElastiCache

- 캐시
- Redis - 클러스터링
- Memcached - 멀티 AZ, Read Replicas 
- 인메모리 데이터 보관 방식, 저지연
- EC2인스턴스를 프로비전해야함
- key-value 보관방식

<br>

#### DynamoDB

- NoSQL
- 서버리스
- key-value 방식으로 ElastiCache를 대체할 수 있음 (단 엘라스틱캐쉬보단 느림)
- 가용성이 높고, Multi AZ, DAX지원

<br>

#### S3

- key - value 저장 방식
- 서버리스, 무한정 확장가능, 최대 5TB의 오프브젝트 사이즈

<br>

#### Athena

- 서버리스, SQL이용
- S3를 쿼리하는 형식
- 쿼리당 페이
- 아웃풋 결과는 S3로 들어갈 수 있다.

<br>

#### RedShift

- OLAP로, 분석을 위한 데이터웨어하우스
- 다른 웨어하우스보다 10배 더 좋은 성능을 보여줌
- 컬럼형 저장 방식
- SQL을 사용
- QuickSight나 태블로와 통합되어 있음
- Multi AZ를 지원하지 않으므로, 스냅샷을 찍어서 백업해야함

<br>

#### Glue

- ETL 서비스
- 데이터를 준비하고 변형하는데 유용
- 서버리스 서비스

<br>

#### Neptune

- 그래프 데이터베이스
- 소셜네트워킹에 주로 사용되는 데이터 베이스
- High relation Data
- 3AZ에 15 Read replicas가능

<br>

#### ElasticSearch

- 검색을 하는 기술로, 모든 필드를 검색 할 수 있고, 부분 일치 항목도 검색할 수 있습니다.
- DynamoDB와 ElasticSearch를 같이 사용해서 좋은 성능을 내고는 함

<br>

#### CloudWatch

- 모든 서비스에 metric을 제공 (모니터링 할 수 있는 지표)

<br>

#### CloudWatch Log

- CloudWatch 로그를 기록하고 저장할 수 있습니다.
- Subscription Filter를 이용해서 원하는 데이터를 분석 할 수 있습니다.

<br>

#### CloudWatch Alarms

- metric에서 트리거할 때 사용됩니다.

<br>

#### AWS CloudWatch Events

- 클라우드와치 이벤트를 통해서 AWS 서비스나 모든 소스에서 일어나는 이벤트를 언터셉트할 수 있습니다. ( EC2 인스턴스 시작, 코드빌드 장애대응, S3 등 )
- CloudTrail 인테그레이션을 통해 API 콜을 할 수 있습니다.
- 스케쥴 or Cron을 할 수 있습니다.

<br>

#### EventEdge

- Cloud Watch Event에 진화형 
- CloudWatch Event는 기본 버스만 사용한다면, EventEdge는 다수의 버스를 생성해서 사용할 수 있습니다.
- 파트너 이벤트 버스 : AWS로부터 이벤트를 전달받는 형태가 아닌, 서비스를 제공하는 것들이나 어플리케이션 형태의 소프트웨어로부터 전달 받습니다. (AWS서비스가 아닌 다른 서비스로도 보낼 수 있음 )
- 커스텀 이벤트 버스 : 어플리케이션의 고유의 이벤트를 생성할 수 있음, 다른 어플리케이션이 이벤트와 상호작용하게 할 수 있음

<br>

#### EventBridge Schema Registry

- 이벤트 브릿지는 버스안에 있는 이벤트를 분석하고 스키마를 해석할 수 있습니다. ( 스키마란 데이터가 어떻게 구성되어 있는지를 의미합니다. )
- 스키마 레지스트리는 코드를 생성해주고 이벤트 버스안에 들어갈 데이터가 어떻게 구성되어야 하는지 설정 ( 시간을 아낄수 있고, 오류도 막을 수 있음 )

<br>

#### EventBridge vs CloudWatch Event

- 이벤트브릿지는 클라우드 와치 이벤트의 연장선입니다.
- 동일한 서비스 API와 엔드포인트를 사용하고, 동일한 서비스 인프라를 사용합니다.
- 단 이벤트 브릿지는 추가적인 기능이 있습니다. ( 커스텀 어플리케이션, 이벤트버스, 스키마 레지스트리 )

<br>

#### CloudTrail

- AWS계정의 거버넌스 컴플라이언스, 그리고 감사권을 부여합니다.
- CloudTrail은 기본적으로 작동합니다.
- AWS 계정에 의한, event의 기록, API 콜 등을 볼 수 있습니다.
- CloudTrail로부터 로그를 가져와, CloudWatch log나 S3로 이동가능
- 모든 리전에서 축적된 모든 기록을 가져올 수 있습니다.
- CloudTrail Insights 를 사용하면, 비정상적인 활동을 검출합니다.

<br>

#### CloudTrail Event Retention

- 기본적으로 이벤트는 90일동안 보관됩니다.
- 이 기간을 넘기 위해서는 S3에 로그를 보낼 수 있게 해야합니다.

<br>

#### AWS Config

- Config는 AWS에 있는 리소스에 대한 감시와 레코드 컴플라이언스를 볼 수 있게 해주는 것입니다.
- 구성을 기록하고, 어떻게 변했는지 알 수 있습니다. 이를 통해 인프라에 어떤 변화가 있었는지 알 수 있습니다.

<br>

#### STS - Security Token Service

- AWS에 대해 단기적 접근을 허용해줍니다.
- 토큰을 발행해 주는데, 이는 단기적으로 1시간까지 유효합니다.
- AssumeRole - 개인계정의 보안강화를 위해 사용, 교차계정 접속을 위해 사용하기도 함
- AssumeRoleWithSAML - SAML을통해 사용자가 합쳐질 때, return credentials을 하는데 도움이 됩니다.
- AssumeRoleWithWebldentity - ID제공자를 통해 로그인할 사용자에 대한 증명을 반환하는 것 ( Facebook Login, Google Login 등) , AWS에서 사용하지 말라고 권고 (Cognito를 사용해라)
- GetSessionToken - 사용자 혹은, AWS계정 root 사용자들을 위한 다중 인증을 위한 것

<br>

#### Identity Federation

- 바깥 사용자들이 AWS 리소스에 접근할 수 있도록 일시적인 역할을 assume합니다.
- 해당 사용자들은 제공된 접근의 역할들의 정체성을 assume합니다.

<br>

#### Microsoft Active Directory(AD)

- 모든 윈도우 서버에서 발견되는 Active Directory Domain Service 
- objects들의 데이터베이스 : 사용자 계정, 컴퓨터, 프린터, 파일 공유 등
- 중앙 보관관리가 이뤄집니다. (계정생성, 허가 등 )
- 오브젝트들은 tree이며, tree들의 그룹은 forest입니다.

<br>

#### AWS Directory Services

- AWS에서 Directory Service를 생성하는 방법 제공
- Managed Microsoft AD - 사용자는 로컬하게 관리, 다중인증 지원
- AD Connector - 직접적 gateway proxy, 사용자들은 On-premise AD로만 관리 
- Simple AD - on-premise 가 없으며, 단독으로 가지고 잇는 형태

<br>

#### AWS Organizations

- AWS 계정을 관리할 수 있도록 하는 서비스
- 주 계정은 Master Account라고 불리며, 변경할 수 없습니다. ( 다른 계정들은 member accounts )
- Member accounts는 오직 한 기관에만 속할 수 있습니다. (이동은 가능)

