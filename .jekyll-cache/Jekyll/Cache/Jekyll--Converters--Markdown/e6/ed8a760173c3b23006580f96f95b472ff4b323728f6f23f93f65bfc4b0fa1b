I"<h1 id="introduction-to-airflow-in-python">Introduction to Airflow in Python</h1>

<h2 id="1-intro-to-airflow">1. Intro to Airflow</h2>

<p><br /></p>

<h4 id="데이터-엔지니어링">데이터 엔지니어링</h4>

<p>컨텍스트에 따라 많은 구체적인 정의가 있지만, 데이터이면의 일반적인 의미는</p>

<p><strong>데이터와 관련된 모든 조치를 취하고 이를 안정적이고 반복 가능하며 유지 관리할 수 있는 프로세스를 만드는 작업</strong></p>

<p><br /></p>

<h4 id="workflow">Workflow</h4>

<p>workflow는 주어진 데이터 엔지니어링 작업을 수행하기 위한 일련의 단계</p>

<ul>
  <li>파일 다운로드</li>
  <li>데이터 복사</li>
  <li>정보 필터링</li>
  <li>데이터베이스 쓰기</li>
</ul>

<p>이러한 작업들이 포함됩니다.</p>

<p>워크플로는 다양한 수준의 복잡성을 가집니다.</p>

<p>일부는 2~3 단계만 있을 수도 있고, 수백 개는 구성 될수도있습니다.</p>

<p>워크 플로의 복잡성은 전적으로 사용자의 요구에 따라 달라집니다.</p>

<p align="center"><img src="/images/post_img/airflow1.PNG" /></p>

<h4 id="airflow">Airflow</h4>

<p>Airflow는 워크 플로를 프로그래밍하는 플랫폼입니다.</p>

<ul>
  <li>생성</li>
  <li>예약</li>
  <li>모니터링</li>
</ul>

<p>이러한 작업을 포함합니다.</p>

<p>Airflow는 다양한 도구와 언어를 사용할 수 있지만, 실제 워크 플로 코드는 <code class="language-plaintext highlighter-rouge">Python</code>으로 작성됩니다.</p>

<p>Airflow는 워크플로우를 <code class="language-plaintext highlighter-rouge">DAG</code> : Directed Acyclic Graph 로 구현합니다.</p>

<p>Airflow는 코드, 명령 줄 또는 내장 웹 인터페이스를 통해 액세스하고 제어 할 수 있습니다.</p>

<p><br /></p>

<h4 id="other-workflow-tools">Other workflow tools</h4>

<ul>
  <li>Luigi (spotify)</li>
  <li>SSIS (Microsoft)</li>
  <li>Bash scripting</li>
</ul>

<p><br /></p>

<h4 id="dags">DAGs</h4>

<p>DAG는 Directed Acyclic Graph를 나타냅니다.</p>

<p>Airflow에서 이것은 워크 플로를 구성하는 작업 집합을 나타냅니다.</p>

<p>작업과 작업 간의 종속성으로 구성</p>

<p>DAG는 DAG에 대한 다양한 세부 정보로 생성 (이름, 시작일, 소유자, 이메일, 알림 옵션 등)</p>

<p><br /></p>

<h4 id="dag-code-example">DAG code example</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">etl_dat</span> <span class="o">=</span> <span class="n">DAG</span><span class="p">(</span>
	<span class="n">dag_id</span><span class="o">=</span><span class="s">'etl_pipeline'</span><span class="p">,</span>
	<span class="n">default_args</span><span class="o">=</span><span class="p">{</span><span class="s">"start_date"</span><span class="p">:</span> <span class="s">"2020-01-08"</span><span class="p">}</span>
<span class="p">)</span>
</code></pre></div></div>

<p><br /></p>

<h4 id="running-a-workflow-in-airflow">Running a workflow in Airflow</h4>

<p>여러 가지 방법중 가장 간단한 방법은 airflow run shell 명령을 사용하는 것입니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">airflow</span> <span class="n">run</span> <span class="o">&lt;</span><span class="n">dag_id</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">task_id</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">start_date</span><span class="o">&gt;</span>

<span class="c1">#example
</span><span class="n">airflow</span> <span class="n">run</span> <span class="n">example</span><span class="o">-</span><span class="n">tel</span> <span class="n">download</span><span class="o">-</span><span class="nb">file</span> <span class="mi">2020</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">10</span>
</code></pre></div></div>

<p><br /></p>

<h4 id="dag">DAG?</h4>

<p>특정 수학적 의미 외에도 DAG 또는 Directed Acyclic Graph에는 다음과 같은 속성이 있습니다.</p>

<p>Directed는 구성 요소 실행 간의 종속성 또는 순서를 나타내는 고유 한 흐름이 있음을 의미</p>

<p>이러한 종속성은 구성 요소 실행 순서를 지정하는 방법에 대한 도구에 컨텍스트를 제공</p>

<p>DAG는 또한 비순환 적이며, 반복되지 않습니다. (이는 이전 DAG를 다시 실행할 수 없음을 의미하는 것이 아니라 개별 구성 요소가 실행 당 한 번만 실행된다는 것을 의미합니다.)</p>

<p>이 경우 Graph는 구성 요소와 구성 요소 간의 관계를 나타냅니다.</p>

<p>DAG라는 용어는 Airflow뿐만 아니라 Apache Spark, Luigi 등의 데이터 엔지니어링에서도 자주 사용됩니다.</p>

<p><br /></p>

<h4 id="dag-in-airflow">DAG in Airflow</h4>

<p>Airflow 내에서 DAG는 Python으로 작성되지만, 다른 언어 또는 기술로 작성된 구성 요소를 사용 할 수 있습니다. 즉, <strong>Python을 사용하여 DAG를 정의하지만,  Bash 스크립트, 기타 실행 파일, Spark 작업 등을 포함합니다.</strong></p>

<p>Airflow DAG는 작업자, 센서 등과 같이 실행할 구성 요소로 구성됩니다. Airflow은 일반적으로 작업이라고 합니다.</p>

<p>Airflow DAG에는 명시 적으로 또는 암시 적으로 정의 된 종속성이 포함됩니다.</p>

<p>이러한 종속성은 실행 순서를 정의하므로 Airflow가 워크 플로 내의 어떤 지점에서 실행되어야하는 구성 요소 예를 들어, 데이터베이스로 가져 오기 전에 파일을 서버로 복사 할 수 있습니다.</p>

<p><br /></p>

<h4 id="define-a-dag">Define a DAG</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow.models</span> <span class="kn">import</span> <span class="n">DAG</span>

<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="n">default_arguments</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'owner'</span><span class="p">:</span> <span class="s">'jdoe'</span><span class="p">,</span>
    <span class="s">'email'</span><span class="p">:</span> <span class="s">'jdoe@datacamp.com'</span><span class="p">,</span>
    <span class="s">'start_date'</span><span class="p">:</span> <span class="n">datetime</span><span class="p">(</span><span class="mi">2020</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="p">}</span>

<span class="n">etl_dag</span> <span class="o">=</span> <span class="n">DAG</span><span class="p">(</span> <span class="s">'etl_workflow'</span><span class="p">,</span> <span class="n">default_args</span><span class="o">=</span><span class="n">default_arguments</span> <span class="p">)</span>
</code></pre></div></div>

<p>먼저 airflow.models 에서 DAG를 선언합니다.</p>

<p>가져온 후에는 기본 인수 사전을 만듭니다. (이러한 속성은 선택사항이지만, Airflow의 런타임 동작을 정의 할 수 있는 많은 기능을 제공)</p>

<p>마지막으로, DAG의 이름 인 etl을 사용하여 첫 번째 인수로 DAG 개체를 정의</p>

<p><br /></p>

<h4 id="dags-on-the-command-line">DAGs on the command line</h4>

<p>Using airflow :</p>

<ul>
  <li>airflow command line program 에는 Airflow 실행의 다양한 측면을 처리하는 많은 하위 명령이 포함</li>
  <li>하위 명령에 대한 도움말 및 설명을 보려면 <code class="language-plaintext highlighter-rouge">airflow -r</code> 명령을 사용</li>
  <li>대부분의 하위명령은, DAGs와 연관</li>
  <li><code class="language-plaintext highlighter-rouge">airflow list_dags</code> 를 사용하여 인식 된 모든 DAG를 볼 수 있습니다.</li>
</ul>

<p><br /></p>

<h4 id="command-line-vs-python">Command line vs Python</h4>

<p>Airflow commnad line을 사용하는 경우와 Python 작성을 하는 경우 비교</p>

<p>Airflow:</p>

<ul>
  <li>Airflow 프로세스를 시작하는 데 사용</li>
  <li>수동으로 DAG 도는 작업을 실행</li>
  <li>로깅 정보를 검토</li>
</ul>

<p>Python:</p>

<ul>
  <li>일반적으로 생성</li>
  <li>실제 데이터 처리 - DAG 편집</li>
</ul>

<p><br /></p>

<h4 id="dags-view">DAGs view</h4>

<p align="center"><img src="/images/post_img/airflow2.PNG" /></p>

<p>이 페이지는 대부분의 시간을 소비하게 될 페이지입니다.</p>

<p>DAG는 사용 가능한 DAG / 워크 플로의 수에 대한 빠른 상태를 제공</p>

<p>Schedule는 일정 (날짜 또는 cron 형식)을 보여줍니다.</p>

<p>Owner는  소유자를 나타냅니다</p>

<p>Recent Tasks는 가장 최근에 실행 된 작업</p>

<p>Last Run은 마지막 시작된 작업</p>

<p>DAG Runs 마지막 3개의 DAG실행</p>

<p>Links는 오른쪽의 링크 영역을 통해 많은 DAG 특정보기에 빠르게 액세스</p>

<p align="center"><img src="/images/post_img/airflow3.PNG" /></p>

<p>DAG의 링크(이름)를 클릭하게 되면 상세 페이지로 접근</p>

<p>DAG 자체 정보에 대한 특정 액세스를 제공</p>

<p>코드의 작업 및 종속성을 보여주는 여러 정보보기 ( 그래프, 트리 및 코드 ), 작업기간, 작업시도, 타이밍, Gantt 차트보기 및 DAG에 대한 특정 세부 정보에 액세스</p>

<p>DAG를 시작하고, 뷰를 새로 고치고 원하는 경우 DAG를 삭제 가능</p>

<p>상세보기는 기본적으로 트리보기로 설정되어 특정 명명된 작업, 사용중인 연산자 및 작업간의 종속성</p>

<p>단어 앞의 원은 작업 / DAG상태를 나타냅니다.</p>

<p>특정 DAG의 경우 generate_random_number라는 작업이 하나 있습니다.</p>

<p align="center"><img src="/images/post_img/airflow4.PNG" /></p>

<p>DAG 그래프보기는 작업 및 종속성을 차트 형식 - DAG의 흐름에 대한 또 다른 보기를 제공합니다.</p>

<p>언제든지 사용중인 연산자와 작업 상태를 볼 수 있습니다.</p>

<p>트리 및 그래프 보기는, 알고 싶은 내용에 따라 다른 정보를 제공 ( 더 자세한 정보를 얻으려면 DAG를 검사 할 때 둘 사이를 이동) 이 뷰에 대해 다시 generate_random_number라는 작업이 있음을 알 수 있습니다.</p>

<p>또한 이미지의 왼쪽 가운데에서 BashOperator 유형임을 알 수 있습니다.</p>

<p align="center"><img src="/images/post_img/airflow5.PNG" /></p>

<p>DAG 코드보기는, DAG를 구성하는 Python 코드의 복사본을 보여줍니다.</p>

<p>코드 보기를 사용하면, UI의 다양한 부분을 클릭하지 않고도, DAG를 정의하는 항목에 쉽게 액세스 할 수 있습니다. (단 코드보기는 읽기 전용)</p>

<p>Airflow를 사용하면서, 가장 적합한 도구를 결정 할 수 있습니다.</p>

<p>모든 DAG 코드 변경은, 실제 DAG 스크립트를 통해 수행해야합니다.</p>

<p>generate_random_number 태스크와 bash 명령 echo $ RANDOM을 실행합니다.</p>

<p align="center"><img src="/images/post_img/airflow6.PNG" /></p>

<p>Browse 메뉴 옵션 아래의 로그 페이지는 Airflow를 사용하는 동안 문제 해결 및 감사 가능을 제공합니다.</p>

<p>여기에는 Airflow 웹 서버 시작, 그래프 또는 트리노드보기, 사용자 생성, DAG 시작 등이 있습니다.</p>

<p>Airflow를 사용할 때 로그를 자주 확인하여 포함 된 정보 유형과 Airflow 설치 뒤에서 일어나는 일에 대해 더 잘 알고 있습니다.</p>

<p><br /></p>

<h4 id="web-ui-vs-commnad-line">Web UI vs commnad line</h4>

<p>기본 설정에 따라 Airflow 웹 UI or Command line 을 선택하는데,</p>

<p>웹 UI는 전체적으로 사용하기가 쉽습니다. Command line은 설정(SSH 등을 통해)에 따라 액세스가 더 간단 할 수 있습니다.</p>

<p><br /></p>

<h2 id="2-implementing-airflow-dags">2. Implementing Airflow DAGs</h2>

<p>Airflow에서 가장 일반적인 작업은 Operators입니다.</p>

<p><br /></p>

<h4 id="operators">Operators</h4>

<p>Airflow는 workflow에서 단일 작업을 나타냅니다</p>

<p>이것은 명령 실행, 이메일 전송, Python 스크립트 실행 등 모든 유형의 작업이 될 수 있습니다.</p>

<p>일반적으로, Airflow 연산자는 독립적으로 실행됩니다. <strong>즉, 작업을 완료하는데 필요한 리소스는 운영자 내에 포함되어 있습니다.</strong></p>

<p>일반적으로 Airflow 연산자는 서로 정보를 공유하지 않습니다. 이는 workflow를 단순화하고 Airflow가 가장 효율적인 방식으로 작업을 실행 할 수 있도록 하기 위한 것입니다. (Operators 간에 정보를 공유 할 수 있습니다.)</p>

<p>Airflow에는 다양한 작업을 수행하는 다양한 연산자가 포함되어 있습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DummyOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="s">'example'</span><span class="p">,</span> <span class="n">dag</span><span class="o">=</span><span class="n">dag</span><span class="p">)</span> <span class="c1"># 문제 해결 또는 아직 구현되지 않은 작업을 위해사용
</span></code></pre></div></div>

<p><br /></p>

<h4 id="bashoperator">BashOperator</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">BashOperator</span><span class="p">(</span>
	<span class="n">task_id</span><span class="o">=</span><span class="s">'bash_example'</span><span class="p">,</span>
	<span class="n">bash_command</span><span class="o">=</span><span class="s">'echo "Example!"'</span><span class="p">,</span>
	<span class="n">dag</span><span class="o">=</span><span class="n">ml_dag</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">BashOperator</span><span class="p">(</span>
	<span class="n">task_id</span><span class="o">=</span><span class="s">'bash_script_example'</span><span class="p">,</span>
	<span class="n">bash_command</span><span class="o">=</span><span class="s">'runcleanup.sh'</span><span class="p">,</span>
	<span class="n">dag</span><span class="o">=</span><span class="n">ml_dag</span><span class="p">)</span>
</code></pre></div></div>

<p>BashOperator는 주어진 Bash명령 또는 스크립트를 실행합니다. 이 명령은 주어진 workflow 에서 의미가있는 Bash가 할 수 있는 거의 모든 것이 될 수 있습니다.</p>

<p>BashOperator에는 세 개의 인수가 필요합니다.</p>

<ul>
  <li>UI, bash 명령 및 해당 명령이 속한 DAG</li>
  <li>BashOperator는 나중에 자동으로 정리되는 임시 디렉토리에서 명령을 실행합니다.</li>
  <li>Bash에 대한 환경 변수를 지정할 수 있습니다. 명령을 실행하여 로컬 시스템에서 수행하는 것처럼 작업 실행을 복제합니다.</li>
  <li>환경 변수에 익숙하지 않은 경우 이러한 변수는 쉘에서 해석하는 런타임 설정입니다. 일반화 된 방식으로 스크립트를 실행하는 동안 유연성을 제공합니다.</li>
</ul>

<p><br /></p>

<h4 id="bashoperator-examples">BashOperator examples</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow.operators.bash_operator</span> <span class="kn">import</span> <span class="n">BashOperator</span>
<span class="n">example_task</span> <span class="o">=</span> <span class="n">BashOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="s">'bash_ex'</span><span class="p">,</span>
                           	<span class="n">bash_command</span><span class="o">=</span><span class="s">'echo 1'</span><span class="p">,</span>
                           	<span class="n">dag</span><span class="o">=</span><span class="n">dag</span><span class="p">)</span>
</code></pre></div></div>

<p>BashOperator를 사용하기 전에 airflow.operator.bash_operator에서 임포트합니다.</p>

<p>task_id를 사용하는 BashOperator를 만듭니다.</p>

<p>bash명령 “echo 1”을 실행하고 연산자를 dag에 할당합니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bash_task</span> <span class="o">=</span> <span class="n">BashOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="s">'clean_address'</span><span class="p">,</span>
                        	<span class="n">bash_command</span><span class="o">=</span><span class="s">'cat addresses.txt | awk "NF==10" &gt; cleaned.txt'</span><span class="p">,</span>
                         	<span class="n">dag</span><span class="o">=</span><span class="n">dag</span><span class="p">)</span>
</code></pre></div></div>

<p>bash_command 에 cat 및 awk 를 사용하여 빠른 데이터 정리 작업을 실행하는 BashOperator입니다.</p>

<p><br /></p>

<h4 id="operator-gotchas">Operator gotchas</h4>

<p>Operator를 운영하는데 몇가지 문제점이 있는데, 가장 큰 문제점은,</p>

<p>개별 Operator가 동일한 위치 또는 환경에서 실행된다는 보장이 없다는 것입니다. (이것은 단지 하나의 연산자가 주어진, 특정 설정이 있는 디렉토리에서 다음 운영자가 동일한 정보에 액세스 할 수 있다는 의미가 아닙니다.)</p>

<p>특히 BashOperator에 대한 환경 변수를 설정해야 할 수 있습니다.</p>

<p>마지막으로 모든 형태의 상승 된 권한으로 작업하는 것이 까다로울 수 있습니다. (상승 된 권한이 무엇인지 확실하지 않을 경우 시스템에서 루트 또는 관리자로 명령을 실행하는 것도 고려)</p>

<p><br /></p>

<h4 id="task">Task</h4>

<ul>
  <li>Airflow 내에서 Task는 인스턴스화 된 연산자입니다.</li>
  <li>
    <p>작업은 일반적으로 Python 코드 내의 변수로 할당됩니다.</p>
  </li>
  <li>Airflow 도구 내에서 이 작업은 변수 이름이 아닌 작업 ID로 참조됩니다.</li>
</ul>

<p><br /></p>

<h4 id="task-dependencies">Task dependencies</h4>

<ul>
  <li>Airflow의 작업 종속성은 작업 완료 순서를 정의합니다.</li>
  <li>필수는 아니지만, 일반적으로 작업 종속성이 있습니다. (작업 종속성이 정의되지 않은 경우 실행은 순서 보장없이 Airflow 자체에서 처리됩니다.)</li>
  <li>작업 종속성을 업스트림 또는 다운 스트림 작업이라고 합니다. (업스트림 작업은 다운스트림 작업 전에 완료해야 함을 의미합니다.)</li>
  <li>Airflow 1.8 이상 부터는, 작업 종속성은 비트 시프트 연산자를 사용하여 정의됩니다.
    <ul>
      <li>업스트림 연산자는 » 입니다.</li>
      <li>다운스트림 연산자는 « 입니다.</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h4 id="upstream-vs-downstream">Upstream vs Downstream</h4>

<p>업스트림과 다운스트림은 혼동하기 쉬운데, 가장 간단한 비유는, 업스트림은 이전을 의미하고 다운스트림은 이후를 의미하는 것입니다.</p>

<p>이것은, 모든 업스트림 작업이 다운 스트림 작업보다 먼저 완료되어야 함을 의미합니다.</p>

<p><br /></p>

<h4 id="simple-task-dependency">Simple task dependency</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">task1</span> <span class="o">=</span> <span class="n">BashOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="s">'first_task'</span><span class="p">,</span>
                     <span class="n">bash_command</span><span class="o">=</span><span class="s">'echo 1'</span><span class="p">,</span>
                     <span class="n">dag</span><span class="o">=</span><span class="n">example_dag</span><span class="p">)</span>

<span class="n">task2</span> <span class="o">=</span> <span class="n">BashOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="s">'second_task'</span><span class="p">,</span>
                     <span class="n">bash_command</span><span class="o">=</span><span class="s">'echo 2'</span><span class="p">,</span>
                     <span class="n">dag</span><span class="o">=</span><span class="n">example_dag</span><span class="p">)</span>
<span class="n">task1</span> <span class="o">&gt;&gt;</span> <span class="n">task2</span> <span class="c1">## or task2 &lt;&lt; task1
</span></code></pre></div></div>

<p>먼저 작업을 정의하고 task1 변수에 할당합니다.</p>

<p>그리고 두 번째 작업을 만들고 task2 변수에 할당합니다.</p>

<p>각 연산자가 정의되고 변수에 할당되면 비트 시프트 연산자를 사용하여 작업 순서를 정의 할 수 있습니다.</p>

<p>task2보다 task1을 먼저 실행하고자 할 때, 가장 읽기 쉬운건 업스트림을 사용하는 방법입니다. (동일한 작업을 다운스트림을 이용해서 역으로 정의 할 수 도 있습니다.)</p>

<p align="center"><img src="/images/post_img/airflow7.PNG" /></p>

<p>작업 및 해당 종속성에 대해 Airflow UI에 표시되는 내용을 살펴보기 위해서는, Airflow 웹 인터페이스 내에서 그래프보기를 하면 됩니다.</p>

<p>작업 영역에서 두 개의 작업, first_task 및 second_task 둘다 존재하지만, 작업 실행 순서는 없습니다.</p>

<p>이것은 bitshift 연산자를 사용하여 작업 종속성을 설정하기 전의 DAG입니다.</p>

<p align="center"><img src="/images/post_img/airflow8.PNG" /></p>

<p>bitshift 연산자를 통해 정의 된 순서로 뷰를 다시 살펴보면 다음과 같습니다. 이전과 달리, 표시되는 작업 순서를 볼 수 있습니다.</p>

<p><br /></p>

<h4 id="multiple-dependencies">Multiple dependencies</h4>

<p>종속성은 필요에 따라 워크 플로를 정의하는데 필요한 만큼 복잡할 수도 있습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">task1</span> <span class="o">&gt;&gt;</span> <span class="n">task2</span> <span class="o">&gt;&gt;</span> <span class="n">task3</span> <span class="o">&gt;&gt;</span> <span class="n">task4</span> <span class="c1"># 1
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">task1</span> <span class="o">&gt;&gt;</span> <span class="n">task2</span> <span class="o">&lt;&lt;</span> <span class="n">task3</span> <span class="c1"># 2
</span></code></pre></div></div>

<p align="center"><img src="/images/post_img/airflow9.PNG" /></p>

<p>즉, 더 명확한 형식으로 두 줄에 동일한 종속성 그래프를 정의 할 수 있습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">task1</span> <span class="o">&gt;&gt;</span> <span class="n">task2</span>
<span class="n">task3</span> <span class="o">&gt;&gt;</span> <span class="n">task2</span> <span class="c1"># 2
</span></code></pre></div></div>

<p><br /></p>

<h4 id="pythonoperator">PythonOperator</h4>

<ul>
  <li>PythonOperator는 Python 함수 또는 호출 가능한 메서드를 실행한다는 점을 제외하면 BashOperator와 유사</li>
  <li>BashOperator와 마찬가지로 taskid, dag 항목 및 대부분의 중요한 것은 파이썬_호출가능한 인수가 문제의 함수 이름으로 설정되어 있다</li>
  <li>필요에 따라 Python callable에 인수 또는 키워드 스타일 인수를 전달할 수 도있습니다.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow.operators.python_operator</span> <span class="kn">import</span> <span class="n">PythonOperator</span>
<span class="k">def</span> <span class="nf">printme</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"This goes is the logs!"</span><span class="p">)</span>
<span class="n">python_task</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
	<span class="n">task_id</span><span class="o">=</span><span class="s">'simple_print'</span><span class="p">,</span>
	<span class="n">python_callable</span><span class="o">=</span><span class="n">printme</span><span class="p">,</span>
	<span class="n">dag</span><span class="o">=</span><span class="n">example_dag</span>
<span class="p">)</span>
</code></pre></div></div>

<p>먼저 airflow.operators.python_operator에서 PythonOperator를 호출합니다.</p>

<p>이후, 함수를 정의하고, 정의되면 python underscore task라는 PythonOperator 인스턴스를 만들고 필요한 인수를 추가합니다.</p>

<p><br /></p>

<h4 id="arguments">Arguments</h4>

<ul>
  <li>PythonOperator는 주어진 작업에 인수 추가를 지원합니나.
    <ul>
      <li>Positional(위치인수)</li>
      <li>Keyword(키워드인수)</li>
    </ul>
  </li>
  <li>PythonOperator로 키워드 인수를 구현하려면, <code class="language-plaintext highlighter-rouge">op_kwargs</code>라는 태스크에 대한 인수를 정의합니다.</li>
</ul>

<p><br /></p>

<h4 id="op_kwargs-example">op_kwargs example</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sleep</span><span class="p">(</span><span class="n">length_of_time</span><span class="p">):</span>
    <span class="n">time</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">length_of_time</span><span class="p">)</span>

<span class="n">sleep_task</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span>
	<span class="n">task_id</span><span class="o">=</span><span class="s">'sleep'</span><span class="p">,</span>
	<span class="n">python_callable</span><span class="o">=</span><span class="n">sleep</span><span class="p">,</span>
	<span class="n">op_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s">'length_of_time'</span><span class="p">:</span><span class="mi">5</span><span class="p">},</span>
	<span class="n">dag</span><span class="o">=</span><span class="n">example_dag</span><span class="p">)</span>
</code></pre></div></div>

<p>시간 인수를 받는 sleep이라는 새 함수를 만들고(sleep시간을 입력받는 함수),</p>

<p>이전에 한것 처럼, PythonOperator를 생성합니다.</p>

<p>op_kwargs 사전을 추가 하는데, 이는 함수에 입력되는 인자입니다. (사전 키는 함수 인수의 이름과 일치해야 합니다., 예기치 않은 키가 포함될 경우, 키워드 인수 오류가 발생합니다.)</p>

<p><br /></p>

<h4 id="emailoperator">EmailOperator</h4>

<ul>
  <li>
    <p>주로 연산자는 <code class="language-plaintext highlighter-rouge">airflow.operators</code> 또는 <code class="language-plaintext highlighter-rouge">airflow.contrib.operators </code> 라이브러리에 있습니다.</p>
  </li>
  <li>또 다른 유용한 연산자는 EmailOperator로, 예상대로 Airflow 작업 내에서 이메일을 보냅니다.</li>
  <li>HTML 컨텐츠 및 첨부 파일을 포함하여 이메일의 일반적인 구성 요소를 포함 할 수 있습니다.</li>
  <li>메시지를 성공적으로 보내려면 Airflow 시스템이 이메일 서버 세부 정보로 구성되어야합니다.</li>
</ul>

<p><br /></p>

<h4 id="emailoperator-example">EmailOperator example</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow.operators.email_operator</span> <span class="kn">import</span> <span class="n">EmailOperator</span>

<span class="n">email_task</span> <span class="o">=</span> <span class="n">EmailOperator</span><span class="p">(</span>
	<span class="n">task_id</span><span class="o">=</span><span class="s">'email_sales_report'</span><span class="p">,</span>
	<span class="n">to</span><span class="o">=</span><span class="s">'sales_manage@example.com'</span><span class="p">,</span>
	<span class="n">subject</span><span class="o">=</span><span class="s">'Automated Sales Report'</span><span class="p">,</span>
	<span class="n">html_content</span><span class="o">=</span><span class="s">'Attached is the latest sales report'</span><span class="p">,</span>
	<span class="n">files</span><span class="o">=</span><span class="s">'latest_sales.xlsx'</span><span class="p">,</span>
	<span class="n">dag</span><span class="o">=</span><span class="n">example_dag</span>
<span class="p">)</span>
</code></pre></div></div>

<p>먼저 airflow.operators.email_operator에서 EmailOperator를 가져와야합니다.</p>

<p>이후, 다음 작업ID로 EmailOperator 인스턴스를 만들 수 있습니다.</p>

<p><br /></p>

<h4 id="dag-runs">DAG Runs</h4>

<ul>
  <li>이는 특정 시점의 워크 플로 인스턴스입니다. ( 예를 들어 현재 실행중인 인스턴스이거나, 지난 화요일 오후 3시에 한번 실행 될 수 있습니다.)</li>
  <li>DAG는 수동으로 실행하거나 DAG 정의시 전달 된 일정 간격 매개 변수를 통해 실행 할 수 있습니다.</li>
  <li>각 DAG 실행은 자체 및 내부 작업에 대한 상태를 유지합니다.
    <ul>
      <li>DAG는 실행 중, 실패 또는 성공 상태 일 수 있습니다.</li>
    </ul>
  </li>
</ul>

<p align="center"><img src="/images/post_img/airflow10.PNG" /></p>

<p>Airflow UI  Browse: DAG Runs 메뉴 옵션에서 모든 DAG 실행을 볼 수 있습니다.</p>

<p>이는 현재 Airflow 인스턴스 내에서 실행 된 DAG에 대한 다양한 세부 정보를 제공합니다.</p>

<p><br /></p>

<h4 id="schedule-details">Schedule details</h4>

<p>DAG를 예약 할 때 예약 요구 사항에 따라 고려해야 할 많은 특성이 있습니다.</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">start_date</code>(시작 날짜 값)은, DAG를 처음으로 예약 할 수 있는 시간을 지정합니다. ( 일반적으로 Python datetime 객체로 정의됩니다. )</p>
  </li>
  <li><code class="language-plaintext highlighter-rouge">end-date</code>(종료 날짜)는 DAG를 예약 할 수 있는 마지막 시간을 나타냅니다.</li>
  <li><code class="language-plaintext highlighter-rouge">max_tries</code>(최대 시도 횟수)는, DAG실행이 완전히 실패하기 전에 재 시도 할 횟수를 나타냅니다.</li>
  <li><code class="language-plaintext highlighter-rouge">schedule_interval</code>(간격)은, 실행을 위해 DAG를 예약하는 빈도를 나타냅니다.</li>
</ul>

<p><br /></p>

<h4 id="schedule-interval">Schedule interval</h4>

<p><code class="language-plaintext highlighter-rouge">schedule_interval</code> represents:</p>

<ul>
  <li>DAG 실행을 예약하는 빈도를 나타냄</li>
  <li>예약은 시작 날짜와 잠재적 종료 날짜 사이에 발생합니다.</li>
  <li>간격은 cron 스타일 구문을 사용하거나 내장 된 사전 설정을 통해 몇 가지 방법으로 할 수 있습니다.</li>
</ul>

<p><br /></p>

<h4 id="cron-syntax">cron syntax</h4>

<p align="center"><img src="/images/post_img/airflow11.PNG" /></p>

<ul>
  <li>
    <p>cron 구문은 Unix cron 도구를 사용하여 작업을 예약하는 형식과 동일</p>
  </li>
  <li>
    <p>공백으로 구분 된 5개의 필드로 구성됩니다. (분, 시간, 일, 월, 요일)</p>
  </li>
  <li>
    <p>모든 필드의 *표는 간격 (분 필드의 *표는 매분 실행을 의미)</p>
  </li>
  <li>
    <p>값 목록은 쉼표로 구분 된 값을 통해 필드에 제공</p>
  </li>
</ul>

<p>&lt;br.</p>

<h4 id="cron-examples">cron examples</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">0</span> <span class="mi">12</span> <span class="o">*</span> <span class="o">*</span> <span class="o">*</span> <span class="c1"># Run daily at noon
</span><span class="o">*</span> <span class="o">*</span> <span class="mi">25</span> <span class="o">*</span> <span class="mi">2</span> <span class="c1"># Run once per minute on Februray 25
</span><span class="mi">0</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">45</span> <span class="o">*</span> <span class="o">*</span> <span class="o">*</span> <span class="o">*</span> <span class="c1"># Run every 15 minutes
</span></code></pre></div></div>

<p><br /></p>

<h4 id="airflow-scheduler-presets">Airflow scheduler presets</h4>

<p>Airflow에는 자주 사용되는 시간 간격을 나타내는 몇 가지 사전 설정 또는 바로 가기 구문 옵션이 있습니다.</p>

<p>Preset:</p>

<ul>
  <li>@hourly - 사전 설정은 시간이 시작 될 때 한시간에 한번 실행됨을 의미합니다.</li>
  <li>@daily</li>
  <li>@weekly</li>
</ul>

<p>cron equivalent:</p>

<ul>
  <li>0 * * * *</li>
  <li>0 0 * * *</li>
  <li>0 0 * * 0</li>
</ul>

<p><br /></p>

<h4 id="special-presets">Special presets</h4>

<p>Airflow에는 일정 간격에 대한 두 가지 특수 사전 설정도 있습니다.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">None</code> 은 DAG를 예약하지 않으며 수동으로 트리거되는 워크 플로에 사용됨을 의미합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">@once</code> 는 DAG를 한 번만 예약하는 것을 의미합니다.</li>
</ul>

<p><br /></p>

<h4 id="schedule_interval-issues">schedule_interval issues</h4>

<p>DAG 실행을 예약 할 때 Airflow는 시작 날짜를 가능한 가장 빠른 값으로 사용하지만, 적어도 하나의 일정 간격이 시작 날짜를 초과 할 때까지 실제로 아무것도 예약하지 않습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">'start_date'</span><span class="p">:</span> <span class="n">datetime</span><span class="p">(</span><span class="mi">2020</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span>
<span class="s">'schdule_interval'</span><span class="p">:</span> <span class="o">@</span><span class="n">daily</span>
</code></pre></div></div>

<p>다음과 같이 주어지면, Airflow는 DAG의 첫 번째 실행에 2020년 2월 26일 날짜를 사용합니다.</p>

<p>새 DAG일정을 추가 할 때 특히 일정 간격이 더 긴 경우 고려하기가 까다로울 수 있습니다.</p>

<p><br /></p>

<h2 id="3-maintaining-and-monitoring-airflow-workflows">3. Maintaining and monitoring Airflow workflows</h2>

<p><br /></p>

<h4 id="sensors">Sensors</h4>

<ul>
  <li>센서는 특정 조건이 참이되기를 기다리는 특별한 종류의 연산자
    <ul>
      <li>생성 대기</li>
      <li>파일, 데이터베이스 레코드 업로드</li>
      <li>
        <p>웹 요청의 특정 응답</p>
      </li>
      <li>센서를 사용하면 조건이 참인지 확인하는 빈도를 정의 할 수 있습니다.</li>
      <li>센서는 작업자 유형이므로, 일반 작업자와 마찬가지로 작업에 할당됩니다.</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h4 id="sensor-details">Sensor details</h4>

<ul>
  <li>모든 센서는  <code class="language-plaintext highlighter-rouge">airflow.sensors.base_sensor_operator</code> 클래스에서 파생됩니다.</li>
  <li>mode, poke_interval 및 timeout을 포함하여 모든 센서에 사용할 수 있는 몇가지 기본 인수가 있습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">mode</code> - 센서에 상태를 확인하는 방법을 알려주며 poke, reschedule 두 가지 옵션이 있습니다.
    <ul>
      <li>mode= ‘poke’ - default값이며, 작업자 슬롯을 포기하지 않고 완료 될 때까지 계속 확인하는 것을 의미</li>
      <li>mode= ‘reschedule’ - 작업자 슬롯을 포기하고 다른 슬롯을 사용할 수 있을 때 까지 기다리는 것을 의미</li>
    </ul>
  </li>
  <li>poke_interval - poke모드에서 사용되며, Airflow 조건을 확인하는 빈도를 알려줍니다. ( Airflow 스케쥴러가 과부하가 걸리지 않도록 하기 위해서는 시간이 1분 이상이여햐 합니다. )</li>
  <li>timeout - 센서 작업을 실패로 표시하기 전에 대기하는 시간입니다.</li>
  <li>센서는 운영자이므로, task_id 및 DAG와 같은 일반 운영자 속성도 포함합니다.</li>
</ul>

<p><br /></p>

<h4 id="file-sensor">File sensor</h4>

<ul>
  <li>
    <p>유용한 센서는 <code class="language-plaintext highlighter-rouge">airflow.contrib.sensors</code> 라이브러리에 있는 FileSensor입니다.</p>
  </li>
  <li>
    <p>FileSensor는 파일 시스템의 특정 위치에 파일이 있는지 확인합니다.</p>
  </li>
  <li>
    <p>주어진 디렉토리 내의 모든 파일을 확인</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">airflow.contrib.sensors.file_sensor</span> <span class="kn">import</span> <span class="n">FileSensor</span>

<span class="n">file_sensor_task</span> <span class="o">=</span> <span class="n">FileSensor</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="s">'file_sense'</span><span class="p">,</span>
                              <span class="n">filepath</span><span class="o">=</span><span class="s">'salesdata.csv'</span><span class="p">,</span>
                              <span class="n">poke_interval</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
                              <span class="n">dag</span><span class="o">=</span><span class="n">sales_report_dag</span><span class="p">)</span>
<span class="n">init_sales_cleanup</span> <span class="o">&gt;&gt;</span> <span class="n">file_sensor_task</span> <span class="o">&gt;&gt;</span> <span class="n">generate_report</span>
</code></pre></div></div>

<p>예시를 보면, FileSensor 개체를 가져온 다음, 파일센서를 정의합니다.</p>

<p>이전에 한 것과 비슷하게, task_id, dag항목을 설정합니다.</p>

<p>filepath 인수는 salesdata로 설정됩니다. 계속하기 전에 이 파일이름이 있는 파일을 찾습니다.</p>

<p>poke_interval을 300초로 설정하면, 참이 될 때 까지 5분마다 확인을 반복합니다.</p>

<p>또한, 비트시프트 연산자를 사용하여 DAG 내에서 센서의 종속성을 정의합니다.</p>

<p><br /></p>

<h4 id="other-sensors">Other sensors</h4>

<p>Airflow에는 다양한 유형의 센서를 사용할 수 있습니다.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ExternalTaskSensor</code> - 별도의 DAG에 있는 작업이 완료 될 때 까지 기다립니다. (하나의 워크 플로를 너무 복잡하게 만들지 않고도, 다른 워크 플로 작업에 느슨하게 연결할 수 있습니다.)</li>
  <li><code class="language-plaintext highlighter-rouge">HttpSensor</code> - 웹 URL을 요청하고 확인할 콘텐츠를 정의 할 수 있습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">SQLSensor</code> - SQL쿼리를 실행하여 콘텐츠를 확인합니다.</li>
  <li>다른 많은 센서가 <code class="language-plaintext highlighter-rouge">airflow.sensors</code> and <code class="language-plaintext highlighter-rouge">airflow.contrib.sensors</code>에 있습니다.</li>
</ul>

<p><br /></p>

<h4 id="why-sensors">Why sensors?</h4>

<ul>
  <li>조건이 언제 참인지 불확실할 때.</li>
  <li>
    <p>조건을 계속 확인하고 싶지만, 반드시 전체 DAG를 즉시 실패하지는 않으려는 경우.</p>
  </li>
  <li>DAG에 주기를 추가하지 않고 반복적으로 검사를 실행하려면 센서를 선택하는 것이 좋습니다.</li>
</ul>

<p><br /></p>

<h4 id="what-is-an-executor">What is an executor?</h4>

<ul>
  <li>Airflow에서 실행기는 워크 플로 내에 정의 된 작업을 실제로 실행하는 구성 요소입니다.</li>
  <li>각 실행기는 작업 세트를 실행하기 위한 다른 기능과 동작을 가지고 있습니다.</li>
  <li>Example executors:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">SequentialExecutor</code></li>
      <li><code class="language-plaintext highlighter-rouge">LocalExecutor</code></li>
      <li><code class="language-plaintext highlighter-rouge">CeleryExecutor</code></li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h4 id="sequentialexecutor">SequentialExecutor</h4>

<ul>
  <li>SequentialExecutor는 Airflow의 기본 실행 엔진입니다.</li>
  <li>한 번에 하나의 작업 만 실행합니다.</li>
  <li>즉, 동일한 시간대에 여러 워크 플로를 예약하면 예상보다 시간이 오래 걸릴 수 있습니다.</li>
  <li>작업의 흐름을 따지는 것이 매우 간단하므로 디버깅에 유용합니다.</li>
  <li>가장 중요한 측면은 매우 기능적이지만, 학습 및 테스트, 작업 리소스의 제한으로 인해 실제로 프로덕션에 권장되지 않습니다.</li>
</ul>

<p><br /></p>

<h4 id="localexecutor">LocalExecutor</h4>

<ul>
  <li>LocalExecutor는 전적으로 단일 시스템에서 실행되는 Airflow의 또 다른 옵션입니다.</li>
  <li>기본적으로 각 작업을 로컬 시스템의 프로세스로 취급하고 많은 작업을 시작할 수 있습니다.</li>
  <li>이 동시성은 시스템의 병렬성이며 사용자가 다음에서 정의합니다.</li>
  <li>지능적으로 정의 된 LocalExecutor는 단일 사용자에게 적합한 선택입니다.</li>
</ul>

<p><br /></p>

<h4 id="celeryexecutor">CeleryExecutor</h4>

<ul>
  <li>여러 시스템이 기본 클러스터로 통신 할 수 잇도록 Python으로 작성된 일반 대기열 시스템입니다.</li>
  <li>여러 Airflow 시스템을 특정 워크 플로 / 작업 세트에 대한 작업자로 구성할 수 있습니다.</li>
  <li>강력한 기능은 설정 및 구성이 훨씬 더 어렵습니다.</li>
  <li>구성하기가 더 어렵지만, 많은 수의 DAG로 작업하거나, 처리량이 증가 할 것으로 예상하는 사람에게 유용</li>
</ul>

<p><br /></p>

<h4 id="determine-your-executor">Determine your executor</h4>

<ul>
  <li><code class="language-plaintext highlighter-rouge">airflow.cfg</code>파일을 통해 할 수 있습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">executor=</code> 를 검색하면, 사용중인 executor를 지정합니다.</li>
</ul>

<p><br /></p>

<h4 id="determine-your-executor-2">Determine your executor 2</h4>

<ul>
  <li><code class="language-plaintext highlighter-rouge">airflow list_dags</code>를 통해서 할 수 있습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">INFO - Using SequentialExecutor</code> 등으로 표시가 됩니다.</li>
</ul>

<p><br /></p>

<h4 id="typical-issues">Typical issues…</h4>

<ul>
  <li>일정에 따라 실행되지 않는 DAG</li>
  <li>단순히 시스템에 로드되지 않는 DAG</li>
  <li>Syntax errors(구문오류)</li>
</ul>

<p><br /></p>

<h4 id="dag-wont-run-on-schedule">Dag won’t run on schedule</h4>

<ul>
  <li>DAG가 일정대로 실행되지 않는 가장 일반적인 이유는, 스케쥴러가 실행되고 있지 않기 때문</li>
</ul>

<p align="center"><img src="/images/post_img/airflow12.PNG" /></p>

<p>스케쥴러 구성 요소가 실행되지 않을 경우, 웹 UI 내에서 오류가 표시</p>

<p>명령 줄에서 <code class="language-plaintext highlighter-rouge">airflow scheduler</code> 를 실행하여 이러한 문제를 해결</p>

<p><br /></p>

<h4 id="dag-wont-run-on-schedule-1">DAG won’t run on schedule</h4>

<ul>
  <li>시작 날짜 또는 마지막 DAG 실행 이후 하나 이상의 일정 간격이 지나지 않았습니다.
    <ul>
      <li>이에 대해 구체적인 수정 사항은 없지만, 원하는 경우 요구 사항에 맞게 시작 날짜 또는 일정 간격을 수정합니다.</li>
    </ul>
  </li>
  <li>실행 프로그램에 작업을 실행하기에 충분한 여유 슬롯이 없을 때</li>
  <li>실행 프로그램을 변경하여 추가 작업을 수행 할 수 있는 항목에 입력합니다. ( LocalExcutor, CeleryExcutor)</li>
  <li>시스템 또는 시스템 리소스, DAG의 일정을 변경합니다.</li>
</ul>

<p><br /></p>

<h4 id="dag-wont-load">DAG won’t load</h4>

<ul>
  <li>로드 되지않은 DAG는 웹 UI 의 DAG보기 또는, airflow list_dags에 출력되지 않습니다.
    <ul>
      <li>가장 먼저 확인해야 할 것은 Python 파일이 예상 DAG 폴더 또는 디렉토리에 있는지</li>
      <li><code class="language-plaintext highlighter-rouge">airflow.cfg</code>를 확인하여 현재 DAG 폴더 설정을 확인</li>
      <li>폴더 경로는 절대 경로여야 합니다.</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h4 id="syntax-errors">Syntax errors</h4>

<ul>
  <li>DAG 목록에는 Python 코드에 하나 이상의 구문 오류가 있을 때</li>
  <li>두가지의 해결방법
    <ul>
      <li>Run <code class="language-plaintext highlighter-rouge">airflow list_dags</code></li>
      <li>Run python3 <dagfile.py></dagfile.py></li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h4 id="slas">SLAs</h4>

<ul>
  <li>SLA는 서비스 수준 계약을 나타냅니다.</li>
  <li>비지니스 세계에서 이것은 종종 가동 시간 또는 가용성 보장입니다.</li>
  <li>Airflow는 이를 약간 다르게 취급합니다. 작업 또는 DAG를 실행하는 데 필요한 시간으로 간주합니다.</li>
  <li>SLA 누락은 작업 또는 DAG가 SLA의 예상 타이밍을 충족하지 못하는 모든 상황입니다.</li>
  <li>SLA 가 누락 된 경우, 시스템 구성에 따라 이메일 경고가 전송되고 로그에 메모가 작성됩니다.</li>
  <li>모든 SLA 누락은 웹 UI의 찾아보기, SLA 누락 메뉴 항목에서 볼 수 있습니다.</li>
</ul>

<p><br /></p>

<h4 id="sla-misses">SLA Misses</h4>

<p>주어진 SLA 누락을 찾아보려면, Browse 에서 SLA 누락 링크를 통해 웹 UI에서 액세스 할 수 있습니다.</p>

<p align="center"><img src="/images/post_img/airflow13.PNG" /></p>

<p>SLA를 놓친 작업과 실패시기에 대한 일반적인 정보를 제공합니다. 또한 SLA가 실패했을 때 이메일이 전송되었는지 여부도 표시합니다.</p>

<p><br /></p>

<h4 id="defining-slas">Defining SLAs</h4>

<ul>
  <li>작업 자체에 대한 <code class="language-plaintext highlighter-rouge">sla</code> 인수를 통한 방법</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">task1</span> <span class="o">=</span> <span class="n">BashOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="s">'sla_task'</span><span class="p">,</span>
                     <span class="n">bash_command</span><span class="o">=</span><span class="s">'runcode.sh'</span><span class="p">,</span>
                     <span class="n">sla</span><span class="o">=</span><span class="n">timedelta</span><span class="p">(</span><span class="n">seconds</span><span class="o">=</span><span class="mi">30</span><span class="p">),</span>
                     <span class="n">dag</span><span class="o">=</span><span class="n">dag</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">default_args</code> 딕셔너리를 사용하고, sla키를 정의하는 방법</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">default_args</span><span class="o">=</span><span class="p">{</span>
    <span class="s">'sla'</span><span class="p">:</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="s">'start_date'</span><span class="p">:</span> <span class="n">datetime</span><span class="p">(</span><span class="mi">2020</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">20</span><span class="p">)</span>
<span class="p">}</span>
<span class="n">dag</span> <span class="o">=</span> <span class="n">DAG</span><span class="p">(</span><span class="s">'sla_dag'</span><span class="p">,</span> <span class="n">default_args</span><span class="o">=</span><span class="n">default_args</span><span class="p">)</span>
</code></pre></div></div>

<p><br /></p>

<h4 id="timedelta-object">timedelta object</h4>

<ul>
  <li>datetime 객체와 함께 datetime 라이브러리에 있습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">from datetime import timedelta</code> 를 통해 쉽게 액세스 할 수 있습니다.</li>
  <li>일, 초, 분, 시간 및 주를 인수로 받습니다.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">timedelta</span><span class="p">(</span><span class="n">seconds</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">timedelta</span><span class="p">(</span><span class="n">weeks</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">hours</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">minutes</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">seconds</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div></div>

<p><br /></p>

<h4 id="general-reporting">General reporting</h4>

<p>보고 목적으로 Airflow에 내장 된 이메일 알림을 사용할 수 있습니다.</p>

<ul>
  <li>Airflow에는 성공, 실패 또는 오류 / 재시도시 메시지를 보내기위한 기본제공 옵션이 있습니다.</li>
  <li>DAG 생성시 전달되는 default_args 딕셔너리의 키를 통해 처리됩니다.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">default_args</span><span class="o">=</span><span class="p">{</span>
    <span class="s">'email'</span><span class="p">:</span> <span class="p">[</span><span class="s">'airflowalerts@datacamp.com'</span><span class="p">],</span>
    <span class="s">'email_on_failure'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
    <span class="s">'email_on_retry'</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
    <span class="s">'email_on_success'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div>

<ul>
  <li>이전에 EmailOperator처럼, 정의 된 Airflow 옵션 중 하나를 벗어나 이메일을 보내는데 유용합니다.</li>
</ul>

<p><br /></p>

<h2 id="4-building-production-pipelines-in-airflow">4. Building production pipelines in Airflow</h2>

<p><br /></p>

<h4 id="what-are-templates">What are templates?</h4>

<ul>
  <li>
    <p>템플릿을 사용하면 DAG 실행 중에 정보를 대체 할 수 있습니다. <strong>즉, 템플릿 정보가 있는 DAG가 실행되면 정보가 해석되고 DAG실행에 포함됩니다.</strong></p>
  </li>
  <li>템플릿은 작업을 정의 할 때 추가적인 유연성을 제공합니다.</li>
  <li>템플릿은 <code class="language-plaintext highlighter-rouge">Jinja</code>템플릿 언어를 사용하여 생성됩니다.</li>
</ul>

<p><br /></p>

<h4 id="non-templated-bashoperator-example">Non-Templated BashOperator example</h4>

<p>관리자가 “읽기” 라는 단어와 파일 목록을 로그 / 출력 등에 에코하도록 요청했습니다.</p>

<p>우리가 현재 알고 있는 것으로 이 작업을 수행한다면, Airflow BashOperator를 사용하여 여러 작업을 생성 할 것 입니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>t1 = BashOperator(
        task_id='first_task',
        bash_command='echo "Reading file1.txt"',
        dag=dag)
t2 = BashOperator(
		task_id='second_task',
		bash_command='echo "Reading file2.txt"',
		dag=dag)
</code></pre></div></div>

<p>처리해야 할 파일이 5개, 10개 또는 심지어 100개 이상인 경우 어떻게 될지 고려 ( 반복적인 코드가 많을 것 )</p>

<p><br /></p>

<h4 id="templated-bashoperator-example">Templated BashOperator example</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>templated_command="""
	echo "Reading "
	"""
t1 = BashOperator(task_id='template_task',
                  bash_command=templated_command,
                  params={'filename':'file1.txt'}
                  dag=example_dag)
</code></pre></div></div>

<p>다음 예시 코드 처럼, params로 파일이름을 주면, 이후 bash_command에서 해당 파일 이름을 변수처럼 사용합니다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>templated_command="""
	echo "Reading "
"""
t1 = BashOperator(task_id='template_task',
                  bash_command=templated_command,
                  params={'filename': 'file1.txt'},
                  dag=example_dag)
t2 = BashOperator(task_id='template_task',
                  bash_command=templated_command,
                  params={'filename': 'file2.txt'}
                  dag=example_dag)
</code></pre></div></div>

<p>2개의 BashOperator를 사용하는 것도 동일합니다.</p>

<p><br /></p>

<h4 id="more-advanced-template">More advanced template</h4>

<p>이전에 작성한 템플릿 코드를 조금더 상향 시켜보겠습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>templated_command="""

"""
t1 = BashOperator(task_id='template_task',
                  bash_command=templated_command,
                  params={'filenames': ['file1.txt', 'file2.txt']}
                  dag=example_dag)
</code></pre></div></div>

<p>이전에 했던 것과, 다르게 for 문을 통해서 하나만 선언해도 2개의 함수가 했던 역할을 할 수 있습니다.</p>

<p><br /></p>

<h4 id="variables">Variables</h4>

<ul>
  <li>템플릿 시스템의 일부로 Airflow는 기본 제공 런타임 변수 세트를 제공합니다.</li>
  <li>DAG 실행, 개별 작업 및 시스템 구성에 대한 다양한 정보를 제공합니다.</li>
  <li>템플릿 예제에는 이중 중괄호 쌍의 ds 인 실행 날짜가 포함됩니다.</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Execution Date:  # YYYY-MM-DD
Execution Date, no dashes:  # YYYYMMDD
Previous Execution date:  # YYYY-MM-DD
Previous Execution date, no dashes:  # YYYYMMDD
DAG object: 
Airflow config object: 
</code></pre></div></div>

<p><br /></p>

<h4 id="macros">Macros</h4>

<p>Airflow 변수 외에도 매크로 변수가 있습니다.</p>

<p>매크로 패키지는 Airflow 템플릿에 대한 다양한 유용한 개체 또는 메서드에 대한 참조를 제공합니다.</p>

<pre><code class="language-txt">macros.datetime : The `datetime.datetime` object
macros.timedelta : The `timedelta` object
macros.uuid : Python's `uuid` object
macros.ds_add('2020-04-15', 5) : 일부 추가 기능도 사용 가능 ( 템플릿 내에서 날짜 계산을 쉽게 수행 할 수 있는 방법을 제공)
</code></pre>

<p><br /></p>

<h4 id="branching">Branching</h4>

<p>Branching은 Ariflow내에서</p>

<ul>
  <li>
    <p>조건부 논리 기능을 제공합니다. (기본적으로 작접자의 결과에 따라 작업을 선택적으로 실행하거나 건너 뛸 수 있음을 의미합니다.)</p>
  </li>
  <li>기본적으로 <code class="language-plaintext highlighter-rouge">BranchPythonOperator</code> 를 사용하고 있습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">from airflow.operators.python_operator import BranchPythonOperator</code> 를 통해 가져옵니다.</li>
  <li>python은 일반 <code class="language-plaintext highlighter-rouge">PythonOperator</code> 와 마찬가지로 호출 가능합니다. ( 이 함수는 task_id의 이름을 반환합니다. )</li>
</ul>

<p><br /></p>

<h4 id="bracnhing-example">Bracnhing example</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">branch_test</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s">'ds_nodash'</span><span class="p">])</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="s">'even_day_task'</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="s">'odd_day_task'</span>

<span class="n">branch_task</span> <span class="o">=</span> <span class="n">BranchPythonOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="s">'branch_task'</span><span class="p">,</span> <span class="n">dag</span><span class="o">=</span><span class="n">dag</span><span class="p">,</span>
                                   <span class="n">provide_context</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                   <span class="n">python_callable</span><span class="o">=</span><span class="n">branch_test</span><span class="p">)</span>

<span class="n">start_task</span> <span class="o">&gt;&gt;</span> <span class="n">branch_task</span> <span class="o">&gt;&gt;</span> <span class="n">even_day_task</span> <span class="o">&gt;&gt;</span> <span class="n">even_day_task2</span>
<span class="n">branch_task</span> <span class="o">&gt;&gt;</span> <span class="n">odd_day_task</span> <span class="o">&gt;&gt;</span> <span class="n">odd_day_task2</span>
</code></pre></div></div>

<p>다음과 같이 **kwargs 인수는 전달 된 유일한 구성 요소입니다. 이것은 함수에 전달 된 키워드 사전에 대한 참조입니다.</p>

<p>함수에서 먼저 kwargs 사전에서 ds_dash키에 액세스합니다. 이를 정수화하여, 나머지가 0인지 확인합니다.</p>

<p>이것은 provide underscore 컨텍스트 인수를 전달하고 True로 설정한다는 점을 제외하면 PythonOperator와 같습니다. 함수에 대한 런타임 변수 및 매크로에 대한 액세스를 제공하도록 Airflow에 지시하는 구성 요소입니다. 이것은 함수 정의에서 kwargs 사전 객체를 통해 참조되는 것입니다.</p>

<p>이러한 종속성을 설정하지 않으면, 모든 작업이 분기 연산자가 반환 한 내용에 관계없이 정상적으로 실행됩니다.</p>

<p align="center"><img src="/images/post_img/airflow14.PNG" /></p>

<p>Airflow UI의 그래프보기를 통해 DAG를 살펴보면 다음과 같습니다.</p>

<p><br /></p>

<h4 id="running-dags--tasks">Running DAGs &amp; Tasks</h4>

<p>구체적인 작업을 하고싶으면,</p>

<p><code class="language-plaintext highlighter-rouge">airflow run &lt;dag_id&gt; &lt;task_id&gt; &lt;date&gt;</code></p>

<p>커맨드라인에서 다음과 같이 사용하세요. 이렇게하면, 지정된 날짜에 실행중인 것처럼 특정 DAG 작업이 실행됩니다.</p>

<p>전체 DAG를 실행하려면,</p>

<p><code class="language-plaintext highlighter-rouge">airflow trigger_dag -e &lt;date&gt; &lt;dag_id&gt;</code></p>

<p><br /></p>

<h4 id="operators-reminder">Operators reminder</h4>

<ul>
  <li>BashOperator -  <code class="language-plaintext highlighter-rouge">bash_command</code> 가필요합니다.</li>
  <li>PythonOperator - <code class="language-plaintext highlighter-rouge">python_callable</code> 가 필요합니다.</li>
  <li>BranchPythonOperator -  <code class="language-plaintext highlighter-rouge">python_callable</code> and <code class="language-plaintext highlighter-rouge">provide_context=True</code> 가 필요합니다. 또한 함수는  <code class="language-plaintext highlighter-rouge">**kwargs</code> 인수로 되어야합니다.</li>
  <li>FileSensor -  <code class="language-plaintext highlighter-rouge">filepath</code>  가 필요합니다.  <code class="language-plaintext highlighter-rouge">mode</code> or <code class="language-plaintext highlighter-rouge">poke_interval</code> 를 설정해야 합니다.</li>
</ul>

<p><br /></p>

<h4 id="template-reminder">Template reminder</h4>

<ul>
  <li>Airflow의 많은 objects 가 템플릿을 사용합니다.</li>
  <li>어떤 필드에서는 템플릿을 지원하지만, 지원하지 않는 것도 있습니다.</li>
  <li>라이브 파이썬 인터프리터를 통해 파이썬 내장 문서를 이용하면, 템플릿을 지원하는지 알 수 있습니다.</li>
</ul>

<p align="center"><img src="/images/post_img/airflow15.PNG" /></p>
:ET